---
layout: project
permalink: /:title/
category: projects
# published: false

meta:
  keywords: "ROS"

project:
  title: "Quadruped Crowd Navigation"
  type: "Jekyll"
  url: "https://github.com/katie-hughes/unitree_crowd_nav"
  logo: "/assets/images/projects/crowdnav/thumbnail.png"
  tech: "ROS 2, C++, Optimal Control"

twomovingpedsoffboard: B1oihg262rQ
twostaticpedsoffboard: rSiHWG69YVA
onboard: BboH0EfObbY
fouronboard: aoRcOXswA70
---

For my capstone project for my MS in Robotics degree at Northwestern University, I am implementing the Bayes Rule Nash Equilibrium ("BRNE") algorithm onto a Unitree Go1 robot for efficient crowd navigation. This post is not complete as I am still actively working on this project!

<br>

{% include youtubePlayer.html id=page.fouronboard %}

<!-- <br> -->

<!-- {% include youtubePlayer.html id=page.onboard %} -->

<br>

# Algorithm

![Description](/assets/images/projects/crowdnav/BRNE-visualization.png)
<center><h6>In this example, two agents are in a hallway. The blue agent wants to walk to the right and the orange agent wants to walk to the left, and their nominal desired paths if no other agents were present are described by the dotted line. The first step is generating samples for each of the agents, as shown in the left panel. After this, the BRNE algorithm uses these randomly generated samples for Bayesian updates to generate optimal trajectories. </h6></center>

<br>

My contribution to this algorithm has primarily involved converting existing code from Python to C++. The Python version of this algorithm uses Numba for optimization. This has successfully worked in field tests, but requires around 20 seconds every time running to compile. Additionally, through stress tests, I found that the runtime blows up when the algorithm has to consider more than 4 agents (including the robot). My C++ implementation of the algorithm uses the Armadillo library for the matrix operations of the BRNE algorithm as well as OpenMP for parallelization. This is comparable with the Numba version of the algorithm for small numbers of pedestrians, but does not see the massive spike that the Python implementation does after 4 agents. In practice, the algorithm should provide trajectory updates at around 10 Hz and should be able to handle up to 5 agents. The C++ algorithm is better suited for this purpose and also scales more efficiently if more agents need to be considered in the future. 

![Description](/assets/images/projects/crowdnav/brne_speed_errorbar_cutoff8.png)
<center><h6>These times were generated running the appropriate BRNE ROS node in simulation using 196 samples per agent and 25 timesteps per sampled trajectory. The scatterplot points are the average computation time and the errorbars are the standard deviation over 100 timer iterations. </h6></center>

# Perception

For localization and pedestrian tracking, I am using a ZED 2i camera from StereoLabs. This camera is mounted on the back of the Unitree and provides updates for both of these topics at 15 Hz.

<!-- <br> -->

<!-- {% include youtubePlayer.html id=page.twostaticpedsoffboard %} -->

<br>

# System Design

At its core, the BRNE algorithm requires pedestrian location data and odometry data. Then, when given a goal position, it can create a trajectory plan that avoids pedestrians. I am using the `unitree_nav` package 
(<a href="https://github.com/ngmor/unitree_nav" target="_blank"><u>available here</u></a>) to process the `cmd_vel` messages that are the result of the BRNE trajectory plan into high level Unitree commands used by their SDK to control the robot. 

![Description](/assets/images/projects/crowdnav/SystemDesignBase.png)
<center><h6>Base Level System Design</h6></center>

I currently, I am using a System76 Adder WS that is mounted onto the back of the Unitree to handle perception data from the ZED (odometry and pedestrian tracking) as well as the actual BRNE algorithm. This is because none of the boards inside of the Unitree (Jetson Nano, Jetson Xavier, and Raspberry Pi) are capable at performing these tasks at the necessary speed. While this performs all of the relevant computation onboard, there are some downsides to this approach. First, it was difficult to design a mount that securely held the laptop on the back of the robot. The robot also has trouble with agile movements and is more prone to falling over from imbalance. With all of the extra weight, the motors also overheat faster, and devices onboard the robot tend to fail sooner (namely the Raspberry Pi provided WIFI hotspot).

![Description](/assets/images/projects/crowdnav/SystemDesignLaptopMount.png)
<center><h6>System Design with a Mounted Laptop</h6></center>

My plan going forward is to replace the onboard laptop with an externally mounted Orin Nano board. This will be able to provide the perception based updates at an appropriately fast rate (15 Hz) and will dramatically reduce the load on the robot. The core BRNE algorithm will execute on my external computer as the Orin Nano does not have good enough CPU for the trajectory optimization calculations. (In the future, it might be possible to use CUDA to optimize the performance of the algorithm to this device, and once again have everything onboard). 

![Description](/assets/images/projects/crowdnav/SystemDesignOrinNano.png)
<center><h6>Proposed System Design with a Mounted Orin Nano</h6></center>

# Acknowledgments

*  <a href="https://muchen-sun.com/" target="_blank"><u>Muchen Sun</u></a>
*  <a href="https://murpheylab.github.io/" target="_blank"><u>Todd Murphey</u></a>
*  Matthew Elwin
*  <a href="https://dlandry97.github.io/Davin_Landry/" target="_blank"><u>Davin Landry</u></a>
*  <a href="https://www.daviddorf.com/" target="_blank"><u>David Dorf</u></a>


<br>

# Video Archive

<br>
{% include youtubePlayer.html id=page.twostaticpedsoffboard %}
<br>
{% include youtubePlayer.html id=page.twomovingpedsoffboard %}
<br>
{% include youtubePlayer.html id=page.onboard %}




<br><br>

